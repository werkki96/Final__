{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T02:10:59.236111Z",
     "start_time": "2024-09-26T02:10:59.227141Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Embedding, multiply, LeakyReLU, ReLU, Softmax\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution, enable_eager_execution\n",
    "disable_eager_execution()\n",
    "# enable_eager_execution()\n",
    "\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T04:58:46.623768Z",
     "start_time": "2024-09-10T04:58:46.616768Z"
    }
   },
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T02:11:04.174128Z",
     "start_time": "2024-09-26T02:11:03.528708Z"
    }
   },
   "source": [
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Physical GPUs:\", len(gpus))\n",
    "    print(\"Logical GPUs:\", len(logical_gpus))\n",
    "\n",
    "except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "gpus"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical GPUs: 1\n",
      "Logical GPUs: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Read data\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:43:57.261786Z",
     "start_time": "2024-09-24T04:43:57.224893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = np.load(\"../data-preprocessing/data/preserve10/x_train.npy\")\n",
    "y_train = np.load(\"../data-preprocessing/data/preserve10/y_train.npy\")\n",
    "x_test = np.load(\"../data-preprocessing/data/preserve10/x_test.npy\")\n",
    "y_test = np.load(\"../data-preprocessing/data/preserve10/y_test.npy\")"
   ],
   "outputs": [],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:43:59.530350Z",
     "start_time": "2024-09-24T04:43:59.523371Z"
    }
   },
   "cell_type": "code",
   "source": "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214914, 31) (214914, 1) (71638, 31) (71638, 1)\n"
     ]
    }
   ],
   "execution_count": 280
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:44:29.174820Z",
     "start_time": "2024-09-24T04:44:29.163839Z"
    }
   },
   "cell_type": "code",
   "source": "y_test",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T06:41:55.591751Z",
     "start_time": "2024-09-12T06:41:55.584812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "#cleans = pd.read_csv(\"../data-preprocessing/sampled_cic2018_data.csv\")\n",
    "#cleans = pd.read_csv(\"../data-preprocessing/data/preserve50/cleans.csv\")\n",
    "\n",
    "def preproc_data(dataset, train_sample: float, pca_dim=31):\n",
    "\n",
    "    # Label encode\n",
    "    le = LabelEncoder()\n",
    "    dataset['label'] = le.fit_transform(dataset['label'])\n",
    "\n",
    "    # Train test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:,:-1],\n",
    "                                                        dataset['label'],\n",
    "                                                        test_size=1-train_sample,\n",
    "                                                        random_state=0)\n",
    "    # Standard scaling\n",
    "    ss = StandardScaler().fit(x_train)\n",
    "\n",
    "    x_train = ss.transform(x_train)\n",
    "    x_test = ss.transform(x_test)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=31).fit(x_train)\n",
    "\n",
    "    x_train = pca.transform(x_train)\n",
    "    x_test = pca.transform(x_test)\n",
    "\n",
    "    # Normalization\n",
    "    norm = Normalizer().fit(x_train)\n",
    "\n",
    "    x_train = norm.transform(x_train)\n",
    "    x_test = norm.transform(x_test)\n",
    "\n",
    "    # Reshaping \n",
    "    y_train = y_train.values.reshape(-1,1)\n",
    "    y_test = y_test.values.reshape(-1,1)\n",
    "    return x_train, x_test, y_train, y_test, pca, ss, norm"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T06:42:02.345446Z",
     "start_time": "2024-09-12T06:42:02.303573Z"
    }
   },
   "source": [
    "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        alpha = tf.random.uniform((self.batch_size, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    \n",
    "class ECGAN():\n",
    "    def __init__(self, \n",
    "                 x_train, \n",
    "                 y_train, \n",
    "                 num_classes: int, \n",
    "                 latent_dim: int, \n",
    "                 batch_size: int,\n",
    "                 n_critic: int,\n",
    "                 conf_thresh: float,\n",
    "                 adv_weight: float):\n",
    "        \"\"\"Implement EC-GAN with an WCGAN-GP and MLP.        \n",
    "        \n",
    "        Attributes\n",
    "        ---------\n",
    "        x_train : numpy.ndarray\n",
    "            Real data without labels used for training.\n",
    "            (Created with sklearn.model_selection.train_test_split\n",
    "        \n",
    "        y_train : numpy.ndarray\n",
    "            Real data labels.\n",
    "            \n",
    "        num_classes : int\n",
    "            Number of data classes. Number of unique elements in y_train.\n",
    "            \n",
    "        data_dim : int\n",
    "            Data dimension. Number of columns in x_train.\n",
    "            \n",
    "        latent_dim : int\n",
    "            Dimension of random noise vector (z), used for training\n",
    "            the generator.\n",
    "            \n",
    "        batch_size : int\n",
    "            Size of training batch in each epoch.\n",
    "        \n",
    "        n_critic : int\n",
    "            Number of times the critic (discriminator) will be trained\n",
    "            in each epoch.\n",
    "            \n",
    "        conf_thresh : float\n",
    "            Confidence threshold. EC-GAN parameter which decides how good\n",
    "            the generated sample needs to be, for it to be fed to the \n",
    "            classifier.\n",
    "        \n",
    "        adv_weight : float\n",
    "            Adverserial weight. EC-GAN parameter which represents the \n",
    "            importance fake data has on classifier training.\n",
    "            Value has been taken from the original paper.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.x_train = x_train.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        \n",
    "        # Store labels as one-hot vectors.\n",
    "        self.y_train_onehot = to_categorical(y_train)\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.data_dim = x_train.shape[1]\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # WCGAN-GP parameters. \n",
    "        self.n_critic = n_critic\n",
    "        \n",
    "        # EC-GAN parameters.\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.adv_weight = adv_weight\n",
    "        \n",
    "        # Log training progress.\n",
    "        self.losslog = []\n",
    "        self.class_acc_log = []\n",
    "        self.class_loss_log = []\n",
    "\n",
    "        # Adam optimizer for WCGAN-GP, suggested by original paper.\n",
    "        optimizer = Adam(learning_rate=0.0005, beta_1=0.05, beta_2=0.9)\n",
    "\n",
    "        # Categorical crossentropy loss function for the classifier.\n",
    "        self.cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "        # Build the generator, critic and classifier\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "        self.classifier = self.build_classifier()\n",
    "\n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic.\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Data input (real sample).\n",
    "        real_data = Input(shape=self.data_dim, name=\"Real_data\")\n",
    "        # Noise input (z).\n",
    "        noise = Input(shape=(self.latent_dim,), name=\"Noise\")\n",
    "        # Label input.\n",
    "        label = Input(shape=(1,), name=\"Label\")\n",
    "        \n",
    "        # Generate data based of noise (fake sample)\n",
    "        fake_data = self.generator([noise, label])\n",
    "        \n",
    "        # Critic (discriminator) determines validity of the real and fake images.\n",
    "        fake = self.critic([fake_data, label])\n",
    "        valid = self.critic([real_data, label])\n",
    "        \n",
    "        # Construct weighted average between real and fake images.\n",
    "        interpolated_data = RandomWeightedAverage(self.batch_size)([real_data, fake_data])\n",
    "        \n",
    "        # Determine validity of weighted sample.\n",
    "        validity_interpolated = self.critic([interpolated_data, label])\n",
    "        \n",
    "        \n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument.\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_data)\n",
    "        # Keras requires function names.\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' \n",
    "        \n",
    "        self.critic_model = Model(\n",
    "            inputs=[real_data, label, noise],\n",
    "            outputs=[valid, fake, validity_interpolated]\n",
    "        )\n",
    "        \n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                        self.wasserstein_loss,\n",
    "                                        partial_gp_loss],\n",
    "                                  optimizer=optimizer,\n",
    "                                  loss_weights=[1, 1, 10])\n",
    " \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze other's layers.\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator.\n",
    "        noise = Input(shape=(self.latent_dim,), name=\"Noise\")\n",
    "        \n",
    "        # Add label to input.\n",
    "        label = Input(shape=(1,), name=\"Label\")\n",
    "        \n",
    "        # Generate data based of noise.\n",
    "        fake_data = self.generator([noise, label])\n",
    "        \n",
    "        # Discriminator determines validity.\n",
    "        valid = self.critic([fake_data, label])\n",
    "\n",
    "        # Defines generator model.\n",
    "        self.generator_model = Model([noise, label], valid)\n",
    "        \n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, \n",
    "                                     optimizer=optimizer)\n",
    "\n",
    "        \n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #   for the Classifier (real)\n",
    "        #-------------------------------\n",
    "        \n",
    "        # Real data classifier training\n",
    "        \n",
    "        real_data = Input(shape=self.data_dim, name=\"Real_data\")\n",
    "        \n",
    "        real_predictions = self.classifier(real_data)\n",
    "        \n",
    "        self.real_classifier_model = Model(real_data, real_predictions)\n",
    "        \n",
    "        self.real_classifier_model.compile(loss=\"categorical_crossentropy\",\n",
    "                                           optimizer=\"adamax\",\n",
    "                                           metrics=[\"accuracy\"])\n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #   for the Classifier (fake)\n",
    "        #-------------------------------\n",
    "        \n",
    "        # Fake data classifier training\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,), name=\"Noise\")\n",
    "        fake_labels = Input(shape=(1,), name=\"Label\")\n",
    "        \n",
    "        real_data = Input(shape=self.data_dim, name=\"Real_data\")\n",
    "        \n",
    "        fake_data = self.generator([noise, fake_labels])\n",
    "        \n",
    "        fake_predictions = self.classifier(fake_data)\n",
    "        \n",
    "        self.fake_classifier_model = Model([noise, fake_labels], fake_predictions)\n",
    "        \n",
    "        self.fake_classifier_model.compile(loss=self.ecgan_loss, \n",
    "                                           optimizer=\"adamax\",\n",
    "                                           metrics=[\"accuracy\"])\n",
    "\n",
    "        \n",
    "        \n",
    "    def ecgan_loss(self, y_true, y_pred):\n",
    "        \"\"\"Calculate loss for fake data predictions.\"\"\"\n",
    "        \n",
    "        max_values = tf.math.reduce_max(y_pred, axis=1)\n",
    "        \n",
    "        max_index = tf.where(tf.math.greater(max_values, self.conf_thresh))\n",
    "        \n",
    "        loss = self.adv_weight * self.cce_loss(y_true[max_index], y_pred[max_index])\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential(name=\"Generator\")\n",
    "        \n",
    "        # First hidden layer.\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Second hidden layer.\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Third hidden layer.\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Output layer.\n",
    "        model.add(Dense(self.data_dim, activation=\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        # Noise and label input layers.\n",
    "        noise = Input(shape=(self.latent_dim,), name=\"Noise\")\n",
    "        label = Input(shape=(1,), dtype=\"int32\", name=\"Label\")\n",
    "        \n",
    "        # Embed labels into onehot encoded vectors.\n",
    "        label_embedding = Flatten(name=\"Flatten\")(Embedding(self.num_classes, self.latent_dim, name=\"Embedding\")(label))\n",
    "        \n",
    "        # Multiply noise and embedded labels to be used as model input.\n",
    "        model_input = multiply([noise, label_embedding], name=\"Multiply\")\n",
    "        \n",
    "        generated_data = model(model_input)\n",
    "\n",
    "        return Model(inputs=[noise, label], \n",
    "                     outputs=generated_data, \n",
    "                     name=\"Generator\")\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential(name=\"Critic\")\n",
    "\n",
    "        # First hidden layer.\n",
    "        model.add(Dense(1024, input_dim=self.data_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        # Second hidden layer.        \n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        # Third hidden layer.\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        # Output layer with linear activation.\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        # Artificial data input.\n",
    "        generated_sample = Input(shape=self.data_dim, name=\"Generated_data\")\n",
    "        # Label input.\n",
    "        label = Input(shape=(1,), dtype=\"int32\", name=\"Label\") \n",
    "        \n",
    "        # Embedd label as onehot vector.\n",
    "        label_embedding = Flatten(name=\"Flatten\")(Embedding(self.num_classes, self.data_dim, name=\"Embedding\")(label))\n",
    "        \n",
    "        # Multiply fake data sample with label embedding to get critic input.\n",
    "        model_input = multiply([generated_sample, label_embedding], name=\"Multiply\")\n",
    "        \n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model(inputs=[generated_sample, label], \n",
    "                     outputs=validity, \n",
    "                     name=\"Critic\")\n",
    "    \n",
    "    def build_classifier(self):\n",
    "        \n",
    "        model = Sequential(name=\"Classifier\")\n",
    "        \n",
    "        # First hidden layer.\n",
    "        model.add(Dense(128, input_dim=self.data_dim))\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Second hidden layer.\n",
    "        model.add(Dense(256))\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(128))\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Output layer.\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Softmax())\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        # Data input.\n",
    "        data = Input(shape=self.data_dim, name=\"Data\")\n",
    "\n",
    "        # CLassifier outout is class predictions vector.\n",
    "        predictions = model(data)\n",
    "        \n",
    "        return Model(inputs=data,\n",
    "                     outputs=predictions,\n",
    "                     name=\"Classifier\")\n",
    "        \n",
    "        \n",
    "    def train(self, epochs):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Adversarial ground truths.\n",
    "        valid = -(np.ones((self.batch_size, 1)))\n",
    "        fake =  np.ones((self.batch_size, 1))\n",
    "        dummy = np.zeros((self.batch_size, 1))\n",
    "\n",
    "        # Number of batches.\n",
    "        self.n_batches = math.floor(self.x_train.shape[0] / self.batch_size)\n",
    "\n",
    "        overhead = self.x_train.shape[0] % self.batch_size\n",
    "         \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # Reset training set.\n",
    "            self.x_train = x_train.copy()\n",
    "            self.y_train = y_train.copy()\n",
    "\n",
    "            # Select random overhead rows that do not fit into batches.\n",
    "            rand_overhead_idx = np.random.choice(range(self.x_train.shape[0]), overhead, replace=False)\n",
    "\n",
    "            # Remove random overhead rows.\n",
    "            self.x_train = np.delete(self.x_train, rand_overhead_idx, axis=0)\n",
    "            self.y_train = np.delete(self.y_train, rand_overhead_idx, axis=0)\n",
    "\n",
    "\n",
    "            # Split training data into batches.\n",
    "            x_batches = np.split(self.x_train, self.n_batches)\n",
    "            y_batches = np.split(self.y_train, self.n_batches)\n",
    "            \n",
    "            for x_batch, y_batch, i in zip(x_batches, y_batches, range(self.n_batches)):   \n",
    "                \n",
    "                if epoch < 5:\n",
    "                    \n",
    "                    for _ in range(self.n_critic):\n",
    "\n",
    "                        # ---------------------\n",
    "                        #  Train Critic\n",
    "                        # ---------------------\n",
    "\n",
    "                        # Generate random noise.\n",
    "                        noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
    "\n",
    "                        # Train the critic.\n",
    "                        d_loss = self.critic_model.train_on_batch(\n",
    "                            [x_batch, y_batch, noise],                                      \n",
    "                            [valid, fake, dummy])\n",
    "\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Generate sample of artificial labels.\n",
    "                    generated_labels = np.random.randint(1, self.num_classes, self.batch_size).reshape(-1, 1)\n",
    "\n",
    "                    # Train generator.\n",
    "                    g_loss = self.generator_model.train_on_batch([noise, generated_labels], valid)\n",
    "\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Classifier\n",
    "                    # ---------------------\n",
    "\n",
    "                    # One-hot encode real labels.\n",
    "                    y_batch = to_categorical(y_batch, self.num_classes)\n",
    "\n",
    "                    # One-hot encode generated labels.\n",
    "                    generated_labels_onehot = to_categorical(generated_labels, self.num_classes)\n",
    "\n",
    "                    real_loss = self.real_classifier_model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "                    fake_loss = self.fake_classifier_model.train_on_batch([noise, generated_labels], generated_labels_onehot)\n",
    "\n",
    "                    # Classifier loss as presented in EC-GAN paper.\n",
    "                    c_loss = (real_loss[0] + fake_loss[0]) / (1 + self.adv_weight)\n",
    "\n",
    "                    avg_acc = np.mean([real_loss[1], fake_loss[1]])\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # ---------------------\n",
    "                    #  Train Classifier\n",
    "                    # ---------------------\n",
    "                    \n",
    "                    # Generate random noise.\n",
    "                    noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
    "\n",
    "                    # Generate sample of artificial labels.\n",
    "                    generated_labels = np.random.randint(1, self.num_classes, self.batch_size).reshape(-1, 1)\n",
    "\n",
    "                    # One-hot encode real labels.\n",
    "                    y_batch = to_categorical(y_batch, self.num_classes)\n",
    "\n",
    "                    # One-hot encode generated labels.\n",
    "                    generated_labels_onehot = to_categorical(generated_labels, self.num_classes)\n",
    "\n",
    "                    real_loss = self.real_classifier_model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "                    fake_loss = self.fake_classifier_model.train_on_batch([noise, generated_labels], generated_labels_onehot)\n",
    "\n",
    "                    # Classifier loss as presented in EC-GAN paper.\n",
    "                    c_loss = (real_loss[0] + fake_loss[0]) / (1 + self.adv_weight)\n",
    "\n",
    "                    avg_acc = np.mean([real_loss[1], fake_loss[1]])\n",
    "\n",
    "\n",
    "                # ---------------------\n",
    "                #  Logging\n",
    "                # ---------------------\n",
    "\n",
    "                self.losslog.append([d_loss[0], g_loss, c_loss])\n",
    "                self.class_loss_log.append([real_loss[0], fake_loss[0], c_loss])\n",
    "                self.class_acc_log.append([real_loss[1], fake_loss[1], avg_acc])\n",
    "\n",
    "                # Plot progress.\n",
    "                # Plot progress.\n",
    "                DLOSS = \"%.4f\" % d_loss[0]\n",
    "                GLOSS = \"%.4f\" % g_loss\n",
    "                CLOSS = \"%.4f\" % c_loss\n",
    "                RLOSS = \"%.4f\" % real_loss[0]\n",
    "                FLOSS = \"%.4f\" % fake_loss[0]\n",
    "                CACC  = \"%.4f\" % real_loss[1]\n",
    "                \n",
    "                if i % 100 == 0:\n",
    "                    print (f\"{epoch} - {i}/{self.n_batches} \\t [D loss: {DLOSS}] [G loss: {GLOSS}] [R loss: {RLOSS} | F loss: {FLOSS} | C loss: {CLOSS} - C acc: {CACC}]\")\n"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T08:48:36.471782Z",
     "start_time": "2024-09-12T08:40:44.860989Z"
    }
   },
   "source": [
    "gan = ECGAN(x_train,\n",
    "            y_train,\n",
    "            num_classes=15,\n",
    "            latent_dim=32,\n",
    "            batch_size=128,\n",
    "            n_critic=5,\n",
    "            conf_thresh=.2,\n",
    "            adv_weight=.1\n",
    "            )\n",
    "\n",
    "gan.train(epochs=10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_172 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " leaky_re_lu_87 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_88 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 1024)              525312    \n",
      "                                                                 \n",
      " leaky_re_lu_89 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 31)                31775     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 697,119\n",
      "Trainable params: 697,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Critic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 1024)              32768     \n",
      "                                                                 \n",
      " leaky_re_lu_90 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " leaky_re_lu_91 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_92 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 689,153\n",
      "Trainable params: 689,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 128)               4096      \n",
      "                                                                 \n",
      " re_lu_42 (ReLU)             (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " re_lu_43 (ReLU)             (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " re_lu_44 (ReLU)             (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 15)                1935      \n",
      "                                                                 \n",
      " softmax_14 (Softmax)        (None, 15)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,951\n",
      "Trainable params: 71,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 - 0/1679 \t [D loss: 8.5157] [G loss: 0.0333] [R loss: 2.6885 | F loss: 0.0000 | C loss: 2.4441 - C acc: 0.0703]\n",
      "0 - 100/1679 \t [D loss: -1.1176] [G loss: -0.8455] [R loss: 0.4453 | F loss: 0.2732 | C loss: 0.6532 - C acc: 0.8828]\n",
      "0 - 200/1679 \t [D loss: -1.1188] [G loss: -0.9787] [R loss: 0.5249 | F loss: 0.2233 | C loss: 0.6802 - C acc: 0.8672]\n",
      "0 - 300/1679 \t [D loss: -1.2682] [G loss: -0.7569] [R loss: 0.4194 | F loss: 0.2357 | C loss: 0.5955 - C acc: 0.8984]\n",
      "0 - 400/1679 \t [D loss: -1.6178] [G loss: -0.4367] [R loss: 0.4674 | F loss: 0.2599 | C loss: 0.6612 - C acc: 0.8750]\n",
      "0 - 500/1679 \t [D loss: -1.9230] [G loss: -0.7567] [R loss: 0.3164 | F loss: 0.2300 | C loss: 0.4967 - C acc: 0.9141]\n",
      "0 - 600/1679 \t [D loss: -1.8737] [G loss: -0.9702] [R loss: 0.2993 | F loss: 0.2167 | C loss: 0.4691 - C acc: 0.9453]\n",
      "0 - 700/1679 \t [D loss: -1.9661] [G loss: -0.9933] [R loss: 0.3432 | F loss: 0.2498 | C loss: 0.5391 - C acc: 0.9219]\n",
      "0 - 800/1679 \t [D loss: -1.6077] [G loss: -1.0312] [R loss: 0.2768 | F loss: 0.2427 | C loss: 0.4723 - C acc: 0.9375]\n",
      "0 - 900/1679 \t [D loss: -2.0372] [G loss: -0.8983] [R loss: 0.4760 | F loss: 0.2081 | C loss: 0.6219 - C acc: 0.8438]\n",
      "0 - 1000/1679 \t [D loss: -1.4964] [G loss: -0.4779] [R loss: 0.2756 | F loss: 0.2616 | C loss: 0.4884 - C acc: 0.9453]\n",
      "0 - 1100/1679 \t [D loss: -1.4785] [G loss: -0.9764] [R loss: 0.2942 | F loss: 0.1956 | C loss: 0.4453 - C acc: 0.9297]\n",
      "0 - 1200/1679 \t [D loss: -2.1437] [G loss: -0.3888] [R loss: 0.1708 | F loss: 0.1786 | C loss: 0.3176 - C acc: 0.9844]\n",
      "0 - 1300/1679 \t [D loss: -1.5954] [G loss: -0.8317] [R loss: 0.3816 | F loss: 0.2113 | C loss: 0.5390 - C acc: 0.9141]\n",
      "0 - 1400/1679 \t [D loss: -1.9791] [G loss: -0.8658] [R loss: 0.2742 | F loss: 0.2127 | C loss: 0.4426 - C acc: 0.9375]\n",
      "0 - 1500/1679 \t [D loss: -1.8514] [G loss: -1.0975] [R loss: 0.2754 | F loss: 0.1947 | C loss: 0.4274 - C acc: 0.9219]\n",
      "0 - 1600/1679 \t [D loss: -1.8989] [G loss: -0.7765] [R loss: 0.3117 | F loss: 0.1978 | C loss: 0.4632 - C acc: 0.9219]\n",
      "1 - 0/1679 \t [D loss: -2.2352] [G loss: -0.7407] [R loss: 0.3044 | F loss: 0.1640 | C loss: 0.4258 - C acc: 0.8984]\n",
      "1 - 100/1679 \t [D loss: -1.8157] [G loss: -0.7948] [R loss: 0.1595 | F loss: 0.1863 | C loss: 0.3144 - C acc: 0.9531]\n",
      "1 - 200/1679 \t [D loss: -1.7386] [G loss: -0.9365] [R loss: 0.4052 | F loss: 0.2238 | C loss: 0.5718 - C acc: 0.8906]\n",
      "1 - 300/1679 \t [D loss: -1.5065] [G loss: -0.7013] [R loss: 0.2542 | F loss: 0.1864 | C loss: 0.4005 - C acc: 0.9453]\n",
      "1 - 400/1679 \t [D loss: -1.8608] [G loss: -0.8210] [R loss: 0.3357 | F loss: 0.2038 | C loss: 0.4904 - C acc: 0.8750]\n",
      "1 - 500/1679 \t [D loss: -1.5458] [G loss: -0.4902] [R loss: 0.2388 | F loss: 0.2117 | C loss: 0.4096 - C acc: 0.9375]\n",
      "1 - 600/1679 \t [D loss: -1.4934] [G loss: -0.6844] [R loss: 0.2765 | F loss: 0.2293 | C loss: 0.4599 - C acc: 0.8984]\n",
      "1 - 700/1679 \t [D loss: -1.3763] [G loss: -0.4630] [R loss: 0.2411 | F loss: 0.1902 | C loss: 0.3922 - C acc: 0.9297]\n",
      "1 - 800/1679 \t [D loss: -1.2316] [G loss: -0.2808] [R loss: 0.2458 | F loss: 0.2267 | C loss: 0.4296 - C acc: 0.9297]\n",
      "1 - 900/1679 \t [D loss: -1.0955] [G loss: -0.0763] [R loss: 0.3310 | F loss: 0.1631 | C loss: 0.4491 - C acc: 0.8984]\n",
      "1 - 1000/1679 \t [D loss: -1.2398] [G loss: -0.3885] [R loss: 0.1756 | F loss: 0.1366 | C loss: 0.2838 - C acc: 0.9844]\n",
      "1 - 1100/1679 \t [D loss: -0.7931] [G loss: 0.4150] [R loss: 0.2810 | F loss: 0.1544 | C loss: 0.3958 - C acc: 0.9219]\n",
      "1 - 1200/1679 \t [D loss: -0.7641] [G loss: 0.4674] [R loss: 0.1235 | F loss: 0.1485 | C loss: 0.2472 - C acc: 0.9922]\n",
      "1 - 1300/1679 \t [D loss: -0.8006] [G loss: 0.3314] [R loss: 0.3044 | F loss: 0.1480 | C loss: 0.4112 - C acc: 0.8984]\n",
      "1 - 1400/1679 \t [D loss: -0.9022] [G loss: 0.1772] [R loss: 0.2852 | F loss: 0.1546 | C loss: 0.3998 - C acc: 0.9219]\n",
      "1 - 1500/1679 \t [D loss: -0.6684] [G loss: 0.2721] [R loss: 0.2904 | F loss: 0.1319 | C loss: 0.3839 - C acc: 0.9141]\n",
      "1 - 1600/1679 \t [D loss: -0.7923] [G loss: 0.3368] [R loss: 0.3650 | F loss: 0.1825 | C loss: 0.4977 - C acc: 0.8828]\n",
      "2 - 0/1679 \t [D loss: -0.8530] [G loss: 0.3008] [R loss: 0.3397 | F loss: 0.1501 | C loss: 0.4453 - C acc: 0.8906]\n",
      "2 - 100/1679 \t [D loss: -1.0126] [G loss: 0.2750] [R loss: 0.1321 | F loss: 0.1545 | C loss: 0.2605 - C acc: 0.9609]\n",
      "2 - 200/1679 \t [D loss: -0.8955] [G loss: 0.2508] [R loss: 0.2878 | F loss: 0.1681 | C loss: 0.4144 - C acc: 0.9297]\n",
      "2 - 300/1679 \t [D loss: -0.7605] [G loss: 0.1613] [R loss: 0.3092 | F loss: 0.1262 | C loss: 0.3959 - C acc: 0.9062]\n",
      "2 - 400/1679 \t [D loss: -0.9420] [G loss: 0.0850] [R loss: 0.3670 | F loss: 0.1609 | C loss: 0.4799 - C acc: 0.8828]\n",
      "2 - 500/1679 \t [D loss: -0.8833] [G loss: 0.1558] [R loss: 0.2400 | F loss: 0.2197 | C loss: 0.4180 - C acc: 0.9297]\n",
      "2 - 600/1679 \t [D loss: -0.7070] [G loss: 0.5597] [R loss: 0.2918 | F loss: 0.1955 | C loss: 0.4430 - C acc: 0.9141]\n",
      "2 - 700/1679 \t [D loss: -0.7415] [G loss: 0.3391] [R loss: 0.2714 | F loss: 0.1523 | C loss: 0.3852 - C acc: 0.9062]\n",
      "2 - 800/1679 \t [D loss: -0.8013] [G loss: 0.1928] [R loss: 0.2628 | F loss: 0.1358 | C loss: 0.3624 - C acc: 0.9219]\n",
      "2 - 900/1679 \t [D loss: -0.7435] [G loss: -0.1216] [R loss: 0.3409 | F loss: 0.1055 | C loss: 0.4058 - C acc: 0.8750]\n",
      "2 - 1000/1679 \t [D loss: -0.7103] [G loss: 0.1204] [R loss: 0.2471 | F loss: 0.1046 | C loss: 0.3197 - C acc: 0.9297]\n",
      "2 - 1100/1679 \t [D loss: -0.7284] [G loss: 0.0047] [R loss: 0.2806 | F loss: 0.1017 | C loss: 0.3476 - C acc: 0.8984]\n",
      "2 - 1200/1679 \t [D loss: -0.7835] [G loss: 0.0402] [R loss: 0.1921 | F loss: 0.0939 | C loss: 0.2600 - C acc: 0.9375]\n",
      "2 - 1300/1679 \t [D loss: -0.6251] [G loss: -0.1241] [R loss: 0.3915 | F loss: 0.0891 | C loss: 0.4370 - C acc: 0.8906]\n",
      "2 - 1400/1679 \t [D loss: -0.7650] [G loss: 0.0915] [R loss: 0.1817 | F loss: 0.0803 | C loss: 0.2381 - C acc: 0.9453]\n",
      "2 - 1500/1679 \t [D loss: -0.6748] [G loss: -0.0224] [R loss: 0.2324 | F loss: 0.0770 | C loss: 0.2813 - C acc: 0.9141]\n",
      "2 - 1600/1679 \t [D loss: -0.7481] [G loss: 0.1924] [R loss: 0.2562 | F loss: 0.0754 | C loss: 0.3014 - C acc: 0.8984]\n",
      "3 - 0/1679 \t [D loss: -0.8246] [G loss: 0.1325] [R loss: 0.2964 | F loss: 0.0774 | C loss: 0.3398 - C acc: 0.8906]\n",
      "3 - 100/1679 \t [D loss: -0.9291] [G loss: 0.0798] [R loss: 0.1239 | F loss: 0.0741 | C loss: 0.1800 - C acc: 0.9766]\n",
      "3 - 200/1679 \t [D loss: -0.7704] [G loss: 0.1800] [R loss: 0.3587 | F loss: 0.1306 | C loss: 0.4448 - C acc: 0.8906]\n",
      "3 - 300/1679 \t [D loss: -0.7303] [G loss: 0.2452] [R loss: 0.3319 | F loss: 0.0899 | C loss: 0.3835 - C acc: 0.8906]\n",
      "3 - 400/1679 \t [D loss: -0.8228] [G loss: 0.3306] [R loss: 0.3596 | F loss: 0.0668 | C loss: 0.3876 - C acc: 0.8594]\n",
      "3 - 500/1679 \t [D loss: -0.7913] [G loss: 0.2314] [R loss: 0.2710 | F loss: 0.0790 | C loss: 0.3183 - C acc: 0.9062]\n",
      "3 - 600/1679 \t [D loss: -0.7593] [G loss: 0.3590] [R loss: 0.2254 | F loss: 0.0475 | C loss: 0.2482 - C acc: 0.9375]\n",
      "3 - 700/1679 \t [D loss: -0.7937] [G loss: 0.1931] [R loss: 0.2175 | F loss: 0.0412 | C loss: 0.2352 - C acc: 0.9375]\n",
      "3 - 800/1679 \t [D loss: -0.6660] [G loss: 0.3086] [R loss: 0.2110 | F loss: 0.0466 | C loss: 0.2342 - C acc: 0.9453]\n",
      "3 - 900/1679 \t [D loss: -0.7476] [G loss: 0.3257] [R loss: 0.2441 | F loss: 0.0526 | C loss: 0.2697 - C acc: 0.8984]\n",
      "3 - 1000/1679 \t [D loss: -0.9071] [G loss: 0.1965] [R loss: 0.2076 | F loss: 0.0510 | C loss: 0.2351 - C acc: 0.9141]\n",
      "3 - 1100/1679 \t [D loss: -0.7762] [G loss: -0.1107] [R loss: 0.3619 | F loss: 0.0340 | C loss: 0.3599 - C acc: 0.8906]\n",
      "3 - 1200/1679 \t [D loss: -0.7684] [G loss: -0.2342] [R loss: 0.1100 | F loss: 0.0318 | C loss: 0.1289 - C acc: 0.9688]\n",
      "3 - 1300/1679 \t [D loss: -0.7907] [G loss: 0.0082] [R loss: 0.3000 | F loss: 0.0396 | C loss: 0.3087 - C acc: 0.9141]\n",
      "3 - 1400/1679 \t [D loss: -0.9675] [G loss: 0.0263] [R loss: 0.2301 | F loss: 0.0462 | C loss: 0.2512 - C acc: 0.9219]\n",
      "3 - 1500/1679 \t [D loss: -0.7751] [G loss: 0.0624] [R loss: 0.3146 | F loss: 0.0306 | C loss: 0.3139 - C acc: 0.8984]\n",
      "3 - 1600/1679 \t [D loss: -0.7797] [G loss: -0.1197] [R loss: 0.2554 | F loss: 0.0258 | C loss: 0.2556 - C acc: 0.9141]\n",
      "4 - 0/1679 \t [D loss: -0.8065] [G loss: -0.0446] [R loss: 0.2006 | F loss: 0.0468 | C loss: 0.2249 - C acc: 0.9297]\n",
      "4 - 100/1679 \t [D loss: -0.9092] [G loss: -0.2162] [R loss: 0.1426 | F loss: 0.0476 | C loss: 0.1729 - C acc: 0.9609]\n",
      "4 - 200/1679 \t [D loss: -0.8425] [G loss: -0.1508] [R loss: 0.3635 | F loss: 0.0335 | C loss: 0.3609 - C acc: 0.8906]\n",
      "4 - 300/1679 \t [D loss: -0.8394] [G loss: -0.3273] [R loss: 0.2164 | F loss: 0.0436 | C loss: 0.2364 - C acc: 0.9453]\n",
      "4 - 400/1679 \t [D loss: -0.7790] [G loss: -0.3335] [R loss: 0.3168 | F loss: 0.0393 | C loss: 0.3238 - C acc: 0.8672]\n",
      "4 - 500/1679 \t [D loss: -0.8644] [G loss: -0.1677] [R loss: 0.2302 | F loss: 0.0431 | C loss: 0.2485 - C acc: 0.9062]\n",
      "4 - 600/1679 \t [D loss: -0.7979] [G loss: -0.3228] [R loss: 0.2088 | F loss: 0.0451 | C loss: 0.2308 - C acc: 0.9297]\n",
      "4 - 700/1679 \t [D loss: -0.7616] [G loss: -0.3694] [R loss: 0.2103 | F loss: 0.0328 | C loss: 0.2210 - C acc: 0.9531]\n",
      "4 - 800/1679 \t [D loss: -0.7362] [G loss: -0.3070] [R loss: 0.2479 | F loss: 0.0193 | C loss: 0.2429 - C acc: 0.9062]\n",
      "4 - 900/1679 \t [D loss: -0.8543] [G loss: -0.3612] [R loss: 0.2769 | F loss: 0.0337 | C loss: 0.2824 - C acc: 0.8906]\n",
      "4 - 1000/1679 \t [D loss: -0.9535] [G loss: -0.4750] [R loss: 0.1354 | F loss: 0.0327 | C loss: 0.1528 - C acc: 0.9609]\n",
      "4 - 1100/1679 \t [D loss: -0.7522] [G loss: -0.3972] [R loss: 0.3333 | F loss: 0.0348 | C loss: 0.3347 - C acc: 0.9141]\n",
      "4 - 1200/1679 \t [D loss: -0.8087] [G loss: -0.4769] [R loss: 0.2107 | F loss: 0.0367 | C loss: 0.2250 - C acc: 0.9297]\n",
      "4 - 1300/1679 \t [D loss: -0.8585] [G loss: -0.4733] [R loss: 0.3019 | F loss: 0.0434 | C loss: 0.3139 - C acc: 0.9141]\n",
      "4 - 1400/1679 \t [D loss: -0.9025] [G loss: -0.4864] [R loss: 0.3118 | F loss: 0.0323 | C loss: 0.3128 - C acc: 0.9297]\n",
      "4 - 1500/1679 \t [D loss: -0.7965] [G loss: -0.5949] [R loss: 0.3384 | F loss: 0.0269 | C loss: 0.3321 - C acc: 0.8906]\n",
      "4 - 1600/1679 \t [D loss: -0.8593] [G loss: -0.4573] [R loss: 0.2307 | F loss: 0.0402 | C loss: 0.2462 - C acc: 0.9219]\n",
      "5 - 0/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2105 | F loss: 0.0318 | C loss: 0.2202 - C acc: 0.9297]\n",
      "5 - 100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1134 | F loss: 0.0237 | C loss: 0.1247 - C acc: 0.9609]\n",
      "5 - 200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.3130 | F loss: 0.0084 | C loss: 0.2923 - C acc: 0.8906]\n",
      "5 - 300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1571 | F loss: 0.0086 | C loss: 0.1507 - C acc: 0.9453]\n",
      "5 - 400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2055 | F loss: 0.0074 | C loss: 0.1935 - C acc: 0.9297]\n",
      "5 - 500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1849 | F loss: 0.0056 | C loss: 0.1732 - C acc: 0.9688]\n",
      "5 - 600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1520 | F loss: 0.0071 | C loss: 0.1447 - C acc: 0.9531]\n",
      "5 - 700/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1330 | F loss: 0.0038 | C loss: 0.1244 - C acc: 0.9375]\n",
      "5 - 800/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1935 | F loss: 0.0039 | C loss: 0.1794 - C acc: 0.9375]\n",
      "5 - 900/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1934 | F loss: 0.0011 | C loss: 0.1768 - C acc: 0.9141]\n",
      "5 - 1000/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1271 | F loss: 0.0095 | C loss: 0.1242 - C acc: 0.9453]\n",
      "5 - 1100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1676 | F loss: 0.0019 | C loss: 0.1541 - C acc: 0.9453]\n",
      "5 - 1200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0780 | F loss: 0.0012 | C loss: 0.0720 - C acc: 0.9844]\n",
      "5 - 1300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2889 | F loss: 0.0049 | C loss: 0.2671 - C acc: 0.9453]\n",
      "5 - 1400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1364 | F loss: 0.0025 | C loss: 0.1262 - C acc: 0.9453]\n",
      "5 - 1500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1785 | F loss: 0.0007 | C loss: 0.1629 - C acc: 0.9375]\n",
      "5 - 1600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1279 | F loss: 0.0028 | C loss: 0.1188 - C acc: 0.9453]\n",
      "6 - 0/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1505 | F loss: 0.0010 | C loss: 0.1377 - C acc: 0.9375]\n",
      "6 - 100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0705 | F loss: 0.0009 | C loss: 0.0648 - C acc: 0.9844]\n",
      "6 - 200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2468 | F loss: 0.0003 | C loss: 0.2246 - C acc: 0.9141]\n",
      "6 - 300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1486 | F loss: 0.0002 | C loss: 0.1354 - C acc: 0.9531]\n",
      "6 - 400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1605 | F loss: 0.0066 | C loss: 0.1519 - C acc: 0.9219]\n",
      "6 - 500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1114 | F loss: 0.0018 | C loss: 0.1029 - C acc: 0.9609]\n",
      "6 - 600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1544 | F loss: 0.0004 | C loss: 0.1407 - C acc: 0.9531]\n",
      "6 - 700/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0840 | F loss: 0.0004 | C loss: 0.0767 - C acc: 0.9688]\n",
      "6 - 800/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1318 | F loss: 0.0003 | C loss: 0.1200 - C acc: 0.9609]\n",
      "6 - 900/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1591 | F loss: 0.0007 | C loss: 0.1453 - C acc: 0.9141]\n",
      "6 - 1000/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0684 | F loss: 0.0015 | C loss: 0.0635 - C acc: 0.9688]\n",
      "6 - 1100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2072 | F loss: 0.0004 | C loss: 0.1887 - C acc: 0.9531]\n",
      "6 - 1200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0488 | F loss: 0.0003 | C loss: 0.0446 - C acc: 0.9922]\n",
      "6 - 1300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2310 | F loss: 0.0019 | C loss: 0.2117 - C acc: 0.9531]\n",
      "6 - 1400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1017 | F loss: 0.0007 | C loss: 0.0930 - C acc: 0.9609]\n",
      "6 - 1500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1625 | F loss: 0.0021 | C loss: 0.1497 - C acc: 0.9453]\n",
      "6 - 1600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1010 | F loss: 0.0003 | C loss: 0.0921 - C acc: 0.9531]\n",
      "7 - 0/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1127 | F loss: 0.0105 | C loss: 0.1121 - C acc: 0.9688]\n",
      "7 - 100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0814 | F loss: 0.0007 | C loss: 0.0747 - C acc: 0.9844]\n",
      "7 - 200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2809 | F loss: 0.0001 | C loss: 0.2555 - C acc: 0.9375]\n",
      "7 - 300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1047 | F loss: 0.0002 | C loss: 0.0954 - C acc: 0.9688]\n",
      "7 - 400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1690 | F loss: 0.0020 | C loss: 0.1554 - C acc: 0.9297]\n",
      "7 - 500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1049 | F loss: 0.0008 | C loss: 0.0960 - C acc: 0.9766]\n",
      "7 - 600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1137 | F loss: 0.0005 | C loss: 0.1038 - C acc: 0.9531]\n",
      "7 - 700/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0799 | F loss: 0.0006 | C loss: 0.0732 - C acc: 0.9688]\n",
      "7 - 800/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1333 | F loss: 0.0003 | C loss: 0.1215 - C acc: 0.9609]\n",
      "7 - 900/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1688 | F loss: 0.0092 | C loss: 0.1618 - C acc: 0.9297]\n",
      "7 - 1000/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0689 | F loss: 0.0003 | C loss: 0.0629 - C acc: 0.9766]\n",
      "7 - 1100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1674 | F loss: 0.0028 | C loss: 0.1547 - C acc: 0.9609]\n",
      "7 - 1200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0484 | F loss: 0.0012 | C loss: 0.0451 - C acc: 0.9844]\n",
      "7 - 1300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2288 | F loss: 0.0004 | C loss: 0.2083 - C acc: 0.9375]\n",
      "7 - 1400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0897 | F loss: 0.0001 | C loss: 0.0816 - C acc: 0.9609]\n",
      "7 - 1500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1454 | F loss: 0.0007 | C loss: 0.1328 - C acc: 0.9531]\n",
      "7 - 1600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0786 | F loss: 0.0002 | C loss: 0.0716 - C acc: 0.9609]\n",
      "8 - 0/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1135 | F loss: 0.0001 | C loss: 0.1033 - C acc: 0.9609]\n",
      "8 - 100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0753 | F loss: 0.0007 | C loss: 0.0691 - C acc: 0.9922]\n",
      "8 - 200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1505 | F loss: 0.0003 | C loss: 0.1371 - C acc: 0.9297]\n",
      "8 - 300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1066 | F loss: 0.0013 | C loss: 0.0981 - C acc: 0.9531]\n",
      "8 - 400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1525 | F loss: 0.0002 | C loss: 0.1388 - C acc: 0.9219]\n",
      "8 - 500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0838 | F loss: 0.0068 | C loss: 0.0824 - C acc: 0.9844]\n",
      "8 - 600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0946 | F loss: 0.0039 | C loss: 0.0895 - C acc: 0.9531]\n",
      "8 - 700/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0823 | F loss: 0.0002 | C loss: 0.0750 - C acc: 0.9688]\n",
      "8 - 800/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1096 | F loss: 0.0047 | C loss: 0.1039 - C acc: 0.9609]\n",
      "8 - 900/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1412 | F loss: 0.0002 | C loss: 0.1285 - C acc: 0.9375]\n",
      "8 - 1000/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0541 | F loss: 0.0003 | C loss: 0.0494 - C acc: 0.9766]\n",
      "8 - 1100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1654 | F loss: 0.0007 | C loss: 0.1510 - C acc: 0.9531]\n",
      "8 - 1200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0419 | F loss: 0.0042 | C loss: 0.0419 - C acc: 1.0000]\n",
      "8 - 1300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1912 | F loss: 0.0054 | C loss: 0.1787 - C acc: 0.9531]\n",
      "8 - 1400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0993 | F loss: 0.0002 | C loss: 0.0905 - C acc: 0.9609]\n",
      "8 - 1500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1198 | F loss: 0.0017 | C loss: 0.1105 - C acc: 0.9453]\n",
      "8 - 1600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0825 | F loss: 0.0010 | C loss: 0.0759 - C acc: 0.9609]\n",
      "9 - 0/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1184 | F loss: 0.0003 | C loss: 0.1079 - C acc: 0.9766]\n",
      "9 - 100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0698 | F loss: 0.0024 | C loss: 0.0656 - C acc: 0.9922]\n",
      "9 - 200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.2205 | F loss: 0.0003 | C loss: 0.2007 - C acc: 0.9297]\n",
      "9 - 300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1073 | F loss: 0.0001 | C loss: 0.0976 - C acc: 0.9609]\n",
      "9 - 400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1271 | F loss: 0.0003 | C loss: 0.1158 - C acc: 0.9297]\n",
      "9 - 500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0939 | F loss: 0.0002 | C loss: 0.0855 - C acc: 0.9766]\n",
      "9 - 600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1190 | F loss: 0.0005 | C loss: 0.1086 - C acc: 0.9688]\n",
      "9 - 700/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0640 | F loss: 0.0002 | C loss: 0.0584 - C acc: 0.9766]\n",
      "9 - 800/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0828 | F loss: 0.0001 | C loss: 0.0753 - C acc: 0.9688]\n",
      "9 - 900/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1238 | F loss: 0.0003 | C loss: 0.1128 - C acc: 0.9297]\n",
      "9 - 1000/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0647 | F loss: 0.0003 | C loss: 0.0592 - C acc: 0.9844]\n",
      "9 - 1100/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1149 | F loss: 0.0005 | C loss: 0.1049 - C acc: 0.9609]\n",
      "9 - 1200/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0558 | F loss: 0.0001 | C loss: 0.0508 - C acc: 0.9766]\n",
      "9 - 1300/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.1325 | F loss: 0.0001 | C loss: 0.1205 - C acc: 0.9609]\n",
      "9 - 1400/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0899 | F loss: 0.0015 | C loss: 0.0830 - C acc: 0.9688]\n",
      "9 - 1500/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0906 | F loss: 0.0010 | C loss: 0.0833 - C acc: 0.9609]\n",
      "9 - 1600/1679 \t [D loss: -0.8695] [G loss: -0.4817] [R loss: 0.0936 | F loss: 0.0000 | C loss: 0.0851 - C acc: 0.9609]\n"
     ]
    }
   ],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:48:56.816649Z",
     "start_time": "2024-09-12T08:48:56.803142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"accuracy\",\n",
    "    mode='max',\n",
    "    patience=5,\n",
    "    min_delta=0.0001\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 260
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:49:01.552011Z",
     "start_time": "2024-09-12T08:48:57.866168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_samples = 50000  # 생성할 데이터 샘플 수\n",
    "noise = np.random.normal(0, 1, (num_samples, gan.latent_dim))  # 넘파이 배열로 노이즈 생성\n",
    "labels = np.random.randint(0, gan.num_classes, num_samples).reshape(-1, 1)  # 넘파이 배열로 라벨 생성\n",
    "# Defines generator model.\n",
    "gen_mo = gan.generator\n",
    "\n",
    "print(noise.shape)\n",
    "\n",
    "# 모델을 사용하여 가짜 데이터 생성\n",
    "generated_data = gen_mo.predict([noise, labels])\n",
    "\n",
    "# 결과 출력\n",
    "print(generated_data.shape)  "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32)\n",
      "(50000, 31)\n"
     ]
    }
   ],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:50:06.248681Z",
     "start_time": "2024-09-12T08:50:02.763748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Classifier를 사용하여 생성된 데이터의 라벨을 예측\n",
    "predicted_labels = gan.classifier.predict(generated_data)\n",
    "\n",
    "# 예측된 라벨 확인\n",
    "predicted_labels_class = np.argmax(predicted_labels, axis=1)  # 라벨을 one-hot에서 원래 라벨로 변환\n",
    "print(f\"Predicted labels: {predicted_labels_class}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [11  9 10 ...  2 10  7]\n"
     ]
    }
   ],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:50:07.057030Z",
     "start_time": "2024-09-12T08:50:06.928944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "# 3. 성능 평가 - Accuracy, F1-Score, Precision, Recall\n",
    "\n",
    "# 라벨을 원래 라벨 형식으로 변환 (실제 라벨과 비교)\n",
    "true_labels = labels.flatten()  # 라벨의 차원 축소 (1D로 변환)\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = accuracy_score(true_labels, predicted_labels_class)\n",
    "\n",
    "# F1-Score 계산\n",
    "f1 = f1_score(true_labels, predicted_labels_class, average='weighted')\n",
    "\n",
    "# Precision 계산\n",
    "precision = precision_score(true_labels, predicted_labels_class, average='weighted')\n",
    "\n",
    "# Recall 계산\n",
    "recall = recall_score(true_labels, predicted_labels_class, average='weighted')\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels_class)\n",
    "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  # False Positives\n",
    "TN = conf_matrix.sum() - (FP + conf_matrix.sum(axis=1) - np.diag(conf_matrix))  # True Negatives\n",
    "FAR = FP / (FP + TN)\n",
    "\n",
    "# 성능 지표 출력\n",
    "print(f\"False Alarm Rate (FAR): {np.mean(FAR)}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Alarm Rate (FAR): 0.004474666666666667\n",
      "Accuracy: 0.9329\n",
      "F1-Score: 0.9097\n",
      "Precision: 0.9641\n"
     ]
    }
   ],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:09:57.416004Z",
     "start_time": "2024-09-12T08:09:45.292020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from experiments.predictions import make_prediction, PredMetrics, get_prediction_metrics, labels\n",
    "from tensorflow.keras.models import load_model\n",
    "pred_lbl = predicted_labels_class.reshape(-1, 1)\n",
    "\n",
    "\n",
    "n_generator = load_model('../models/10_classifier_standalone.h5')\n",
    "n_generator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "#predictions = make_prediction(gan.c, pd.DataFrame(generated_data), pd.DataFrame(pred_lbl))\n",
    "predictions = make_prediction(n_generator, pd.DataFrame(generated_data), pd.DataFrame(pred_lbl))\n",
    "pred_metrics = get_prediction_metrics(predictions)\n"
   ],
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "data Generator"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T07:35:43.878648Z",
     "start_time": "2024-09-12T07:35:43.874661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ],
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:52:25.325438Z",
     "start_time": "2024-09-12T02:52:24.522904Z"
    }
   },
   "cell_type": "code",
   "source": "n_generator = load_model('../models/10_generator_ecgan.h5')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:52:28.046083Z",
     "start_time": "2024-09-12T02:52:28.031134Z"
    }
   },
   "cell_type": "code",
   "source": "n_generator.compile(optimizer='adam', loss='binary_crossentropy')",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T05:01:11.225139Z",
     "start_time": "2024-09-12T05:01:09.825545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latent_dim = 32  # GAN에서 사용된 latent_dim에 맞춰 조정\n",
    "num_samples = 50000  # 생성할 가짜 데이터 샘플 수\n",
    "num_class = 15 # 공격 유형 종류 개수\n",
    "\n",
    "n_noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "n_labels = np.random.randint(0, num_class, num_samples).reshape(-1, 1)\n",
    "\n",
    "n_generated_data = n_generator.predict([n_noise, n_labels])\n",
    "\n",
    "\n",
    "print(\"Generated Data:\")\n",
    "print(n_generated_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Data:\n",
      "[[-0.68268234  0.17495912  0.20577762 ... -0.18258724 -0.18722193\n",
      "   0.01443134]\n",
      " [-0.79286534 -0.11340783 -0.31293982 ...  0.05823324 -0.18581195\n",
      "   0.3014445 ]\n",
      " [-0.4163572  -0.03150876 -0.10934426 ... -0.02998968 -0.2822905\n",
      "   0.01190818]\n",
      " ...\n",
      " [ 0.20412876 -0.19480619 -0.7785817  ... -0.06264126 -0.127092\n",
      "   0.2526062 ]\n",
      " [-0.71806127 -0.09468994  0.21338812 ... -0.13885799 -0.45534924\n",
      "  -0.3653347 ]\n",
      " [-0.04258306 -0.043513   -0.82570744 ... -0.13206884 -0.61264884\n",
      "  -0.27819312]]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FID score"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T05:01:14.963699Z",
     "start_time": "2024-09-12T05:01:14.944527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_generated_data.shape\n",
    "n_generated_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68268234,  0.17495912,  0.20577762, ..., -0.18258724,\n",
       "        -0.18722193,  0.01443134],\n",
       "       [-0.79286534, -0.11340783, -0.31293982, ...,  0.05823324,\n",
       "        -0.18581195,  0.3014445 ],\n",
       "       [-0.4163572 , -0.03150876, -0.10934426, ..., -0.02998968,\n",
       "        -0.2822905 ,  0.01190818],\n",
       "       ...,\n",
       "       [ 0.20412876, -0.19480619, -0.7785817 , ..., -0.06264126,\n",
       "        -0.127092  ,  0.2526062 ],\n",
       "       [-0.71806127, -0.09468994,  0.21338812, ..., -0.13885799,\n",
       "        -0.45534924, -0.3653347 ],\n",
       "       [-0.04258306, -0.043513  , -0.82570744, ..., -0.13206884,\n",
       "        -0.61264884, -0.27819312]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:27:16.699386Z",
     "start_time": "2024-09-24T04:27:12.163313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator = load_model('../models/10_generator_ecgan.h5')\n",
    "\n",
    "generator.compile(optimizer='adamax', loss='categorical_crossentropy')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "execution_count": 277
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:27:30.042291Z",
     "start_time": "2024-09-24T04:27:30.010293Z"
    }
   },
   "cell_type": "code",
   "source": "generator.x_train",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'x_train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[278], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_train\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Functional' object has no attribute 'x_train'"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T05:01:18.641667Z",
     "start_time": "2024-09-12T05:01:18.636683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# real_data = Input(shape=gan_4.data_dim, name=\"Real_data\")\n",
    "real_data = gan.x_train\n",
    "print(real_data.shape)\n",
    "real_data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214912, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.85775220e-01,  1.18859810e-01, -2.33336013e-01, ...,\n",
       "         1.42831494e-03, -1.49054324e-01, -3.82786162e-02],\n",
       "       [-3.49671383e-01, -1.19709206e-02, -1.96306732e-02, ...,\n",
       "        -1.09954130e-02,  5.84614070e-02, -3.87464246e-01],\n",
       "       [-4.20425564e-01, -9.41638142e-03,  9.02171118e-02, ...,\n",
       "         2.76713237e-03, -1.50640826e-01, -3.32339831e-02],\n",
       "       ...,\n",
       "       [-6.07627877e-01, -1.64936326e-02,  4.88910680e-02, ...,\n",
       "        -1.89801871e-03, -7.00946179e-03,  3.23437019e-02],\n",
       "       [ 5.13103114e-01,  1.94842904e-02, -6.77089951e-01, ...,\n",
       "        -5.40587256e-04, -2.47992226e-02,  1.16792042e-01],\n",
       "       [ 4.99980194e-01,  5.12125608e-02,  1.35006774e-01, ...,\n",
       "        -1.52033428e-02, -7.36446875e-02, -5.18328094e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:23:51.861765Z",
     "start_time": "2024-09-24T04:23:51.854788Z"
    }
   },
   "cell_type": "code",
   "source": "gan",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ECGAN at 0x19698e57b20>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 274
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:26:54.647675Z",
     "start_time": "2024-09-12T08:26:54.628254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "# FID 계산 함수\n",
    "def calculate_fid(real_data, generated_data):\n",
    "    # 평균과 공분산 계산\n",
    "    mu1, sigma1 = np.mean(real_data, axis=0), np.cov(real_data, rowvar=False)\n",
    "    mu2, sigma2 = np.mean(generated_data, axis=0), np.cov(generated_data, rowvar=False)\n",
    "\n",
    "    # 평균 차이 제곱합 계산\n",
    "    ssdiff = np.sum((mu1 - mu2)**2)\n",
    "\n",
    "    # 공분산 행렬의 곱의 제곱근 계산\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "\n",
    "    # 공분산 행렬에 복소수 값이 발생하는 경우 실수로 변환\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    # Fréchet Distance 계산\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "    return fid\n"
   ],
   "outputs": [],
   "execution_count": 256
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:55:51.245195Z",
     "start_time": "2024-09-12T08:55:51.104999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 데이터 정규화 (0과 1 사이로 변환)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# 실제 데이터 정규화\n",
    "x_train_scaled = scaler.fit_transform(gan.x_train)\n",
    "\n",
    "generated_data_scaled = scaler.transform(generated_data)\n",
    "norm = Normalizer().fit(x_train_scaled)\n",
    "\n",
    "x_train_scaled\\\n",
    "    = norm.transform(x_train_scaled)\n",
    "generated_data_scaled = norm.transform(generated_data_scaled)\n",
    "\n",
    "# FID 계산\n",
    "real_data = x_train_scaled\n",
    "fid_score = calculate_fid(generated_data_scaled, np.array(real_data))\n",
    "print(f\"FID Score: {fid_score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 0.23649834826424593\n"
     ]
    }
   ],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:51:27.693357Z",
     "start_time": "2024-09-12T08:51:27.640027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FID 계산\n",
    "real_data = gan.x_train\n",
    "fid_score = calculate_fid(generated_data, np.array(real_data))\n",
    "print(f\"FID Score: {fid_score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 3.21723348627425\n"
     ]
    }
   ],
   "execution_count": 269
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T05:21:57.328704Z",
     "start_time": "2024-09-12T05:21:57.311759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.save(\"./gen_x_test.npy\", generated_data)\n",
    "np.save(\"./gen_y_test.npy\", labels)\n",
    "\n",
    "np.save(\"./n_gen_x_test.npy\", n_generated_data)\n",
    "np.save(\"./n_gen_y_test.npy\", n_labels)\n"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T05:54:28.680099Z",
     "start_time": "2024-09-12T05:54:25.081484Z"
    }
   },
   "cell_type": "code",
   "source": "n_generator = load_model('../models/10_generator_ecgan.h5')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:40:28.506598Z",
     "start_time": "2024-09-12T08:40:27.105942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. real_data와 generated_data 예시 생성\n",
    "# real_data = np.random.randn(real_data, 31)   # 실제 데이터\n",
    "# generated_data = np.random.randn(generated_data, 31)  # 생성된 데이터\n",
    "\n",
    "# 2. 특정 피처 선택 (예: 첫 번째 피처 0번)\n",
    "real_feature = real_data[:, 0]\n",
    "generated_feature = generated_data[:, 0]\n",
    "\n",
    "# 3. 히스토그램으로 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 실제 데이터 히스토그램 (파란색)\n",
    "plt.hist(real_feature, bins=30, alpha=0.5, label=\"Real Data\", color='blue')\n",
    "\n",
    "# 생성된 데이터 히스토그램 (빨간색)\n",
    "plt.hist(generated_feature, bins=30, alpha=0.5, label=\"Generated Data\", color='red')\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.xlabel(\"Feature Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Feature 0 Distribution (Real vs Generated Data)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "autodetected range of [nan, nan] is not finite",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[258], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m plt\u001B[38;5;241m.\u001B[39mhist(real_feature, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReal Data\u001B[39m\u001B[38;5;124m\"\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# 생성된 데이터 히스토그램 (빨간색)\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhist\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated_feature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGenerated Data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mred\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# 그래프 세부 설정\u001B[39;00m\n\u001B[0;32m     22\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature Value\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ecs\\lib\\site-packages\\matplotlib\\pyplot.py:2685\u001B[0m, in \u001B[0;36mhist\u001B[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001B[0m\n\u001B[0;32m   2679\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mhist)\n\u001B[0;32m   2680\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhist\u001B[39m(\n\u001B[0;32m   2681\u001B[0m         x, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28mrange\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, density\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2682\u001B[0m         cumulative\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, bottom\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, histtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbar\u001B[39m\u001B[38;5;124m'\u001B[39m, align\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmid\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   2683\u001B[0m         orientation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m'\u001B[39m, rwidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2684\u001B[0m         label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, stacked\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2685\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhist\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2686\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbins\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdensity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdensity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2687\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcumulative\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcumulative\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbottom\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbottom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhisttype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhisttype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2688\u001B[0m \u001B[43m        \u001B[49m\u001B[43malign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malign\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morientation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morientation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2689\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstacked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstacked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2690\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ecs\\lib\\site-packages\\matplotlib\\__init__.py:1447\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1444\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1445\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1446\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1447\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1449\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1450\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1451\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ecs\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6651\u001B[0m, in \u001B[0;36mAxes.hist\u001B[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001B[0m\n\u001B[0;32m   6647\u001B[0m \u001B[38;5;66;03m# Loop through datasets\u001B[39;00m\n\u001B[0;32m   6648\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(nx):\n\u001B[0;32m   6649\u001B[0m     \u001B[38;5;66;03m# this will automatically overwrite bins,\u001B[39;00m\n\u001B[0;32m   6650\u001B[0m     \u001B[38;5;66;03m# so that each histogram uses the same bins\u001B[39;00m\n\u001B[1;32m-> 6651\u001B[0m     m, bins \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistogram\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbins\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhist_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6652\u001B[0m     tops\u001B[38;5;241m.\u001B[39mappend(m)\n\u001B[0;32m   6653\u001B[0m tops \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(tops, \u001B[38;5;28mfloat\u001B[39m)  \u001B[38;5;66;03m# causes problems later if it's an int\u001B[39;00m\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mhistogram\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ecs\\lib\\site-packages\\numpy\\lib\\histograms.py:792\u001B[0m, in \u001B[0;36mhistogram\u001B[1;34m(a, bins, range, normed, weights, density)\u001B[0m\n\u001B[0;32m    680\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;124;03mCompute the histogram of a set of data.\u001B[39;00m\n\u001B[0;32m    682\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    788\u001B[0m \n\u001B[0;32m    789\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    790\u001B[0m a, weights \u001B[38;5;241m=\u001B[39m _ravel_and_check_weights(a, weights)\n\u001B[1;32m--> 792\u001B[0m bin_edges, uniform_bins \u001B[38;5;241m=\u001B[39m \u001B[43m_get_bin_edges\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbins\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[38;5;66;03m# Histogram is an integer or a float array depending on the weights.\u001B[39;00m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ecs\\lib\\site-packages\\numpy\\lib\\histograms.py:426\u001B[0m, in \u001B[0;36m_get_bin_edges\u001B[1;34m(a, bins, range, weights)\u001B[0m\n\u001B[0;32m    423\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_equal_bins \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    424\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`bins` must be positive, when an integer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 426\u001B[0m     first_edge, last_edge \u001B[38;5;241m=\u001B[39m \u001B[43m_get_outer_edges\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(bins) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    429\u001B[0m     bin_edges \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(bins)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ecs\\lib\\site-packages\\numpy\\lib\\histograms.py:323\u001B[0m, in \u001B[0;36m_get_outer_edges\u001B[1;34m(a, range)\u001B[0m\n\u001B[0;32m    321\u001B[0m     first_edge, last_edge \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mmin(), a\u001B[38;5;241m.\u001B[39mmax()\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (np\u001B[38;5;241m.\u001B[39misfinite(first_edge) \u001B[38;5;129;01mand\u001B[39;00m np\u001B[38;5;241m.\u001B[39misfinite(last_edge)):\n\u001B[1;32m--> 323\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    324\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautodetected range of [\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m] is not finite\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(first_edge, last_edge))\n\u001B[0;32m    326\u001B[0m \u001B[38;5;66;03m# expand empty range to avoid divide by zero\u001B[39;00m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_edge \u001B[38;5;241m==\u001B[39m last_edge:\n",
      "\u001B[1;31mValueError\u001B[0m: autodetected range of [nan, nan] is not finite"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 258
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T08:52:49.283008Z",
     "start_time": "2024-09-12T08:52:45.138146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. real_data와 generated_data 예시 생성\n",
    "#real_data = np.random.randn(411136, 31)   # 실제 데이터\n",
    "#generated_data = np.random.randn(10000, 31)  # 생성된 데이터\n",
    "\n",
    "# 2. PCA로 2차원으로 차원 축소\n",
    "pca = PCA(n_components=2)\n",
    "real_data_2d = pca.fit_transform(real_data)\n",
    "generated_data_2d = pca.transform(generated_data)\n",
    "\n",
    "norm = Normalizer().fit(real_data_2d)\n",
    "\n",
    "real_data_2d = norm.transform(real_data_2d)\n",
    "generated_data_2d = norm.transform(generated_data_2d)\n",
    "\n",
    "# 3. 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 실제 데이터 점으로 표시 (파란색)\n",
    "plt.scatter(real_data_2d[:, 0], real_data_2d[:, 1], label=\"Real Data\", alpha=0.5, c='blue', s=10)\n",
    "\n",
    "# 생성된 데이터 점으로 표시 (빨간색)\n",
    "plt.scatter(generated_data_2d[:, 0], generated_data_2d[:, 1], label=\"Generated Data\", alpha=0.5, c='red', s=10)\n",
    "\n",
    "# 제목 및 범례 추가\n",
    "plt.title(\"Real Data vs Generated Data (PCA 2D Projection)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 271
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "326.516px",
    "left": "920.969px",
    "right": "20px",
    "top": "81px",
    "width": "734.469px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
